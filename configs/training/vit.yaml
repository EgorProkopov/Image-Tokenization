seed: 239

training:
  train_batch_size: 48
  val_batch_size: 48
  num_workers: 12
  
  accelerator: "gpu"
  devices: [0]
  strategy: "auto"

  max_epochs: 10
  lr: 5e-5
  warmup_steps: 1000

logging:
  log_every_n_steps: 100
  val_check_interval: 500
  checkpoints_dir: "checkpoints"
  log_dir: "logs"
  

clearml:
  project_name: "tokenizers"
  task_name: "vit_tokenizer"
